새로운 노트
2023.05.26 금 오후 1:12 ・ 103분 55초
이준택

AI 요약
00:00
인공지능 관련 뉴스
- 지난주에 스터디 인원이 2명이라 스터디를 안 했고 오늘이 첫 스터디임
- 쓸데없는 뉴스를 다 빼고 인공지능 관련된 것만 정리를 해놓은 게 아까워서 잠깐 보겠음
- 비트코인은 블록 안에 코드를 넣을 수 있는 서드 파티를 개발해서 난리임

04:56
한국어에 특화된 데이터
- gpt 4부터는 한국어도 엄청 잘 됨
- 데이터가 더 중요한데 한글에 특성화된 데이터는 구글보다 많음
- 한국의 기업들이 희망이 있겠나 싶음

07:46
구글, 이미지 바인드 공개
- 구글 아이오에서 오픈 소스가 너무 빨리 발전하니까 대기업끼리의 대결이 아니고 영리 법인과 오픈 소스의 대결이 돼 버리는 양상임
- 이미지 바인드라는 ai 모델을 오픈 소스로 공개함

12:36
테슬라, 일론 머스크 트위터 인수
- 메타가 알파카를 만들게 된 베이스 모델임
- 테슬라 쪽에 일론 머스크가 트위터를 샀음
- 테슬라 쪽 진영이랑 메타 쪽 진영이랑 대결 구도가 됨

15:23
라지 랭기지 모델
- 라지 레니즈 모델은 돌리려면 어마어마하게 큰 gpu하고 필요함
- 라지 랭기지 모델은 연산해서 임베딩 벡터 테이블에 보고 결과값과 가장 가까운 테이블을 찾으면 바로 찾을 수 있음
- 내부적으로 알고리즘을 짤 때는 사람이 다 컨트롤해서 매뉴얼하게 다 짰는데 이제는 ai 코어 알고리즘을 스스로 만들어냄

19:28
디퓨전 영상
- 디퓨전 영상은 모두의 연구소에 들어가면 재생 목록에 있음
- mod pop에 dpio 세미나 한 개 있음
- 2회 차부터 할 건데 한 페이지 한 페이지 자르면서 갈 것임
- 이해 안 되거나 궁금한 건 끝까지 물어보길 바람

21:38
디퓨전의 개념
- 2014년부터 20년까지의 생성 요약을 했던 것을 요약해 보겠음
- 디퓨전에 관심을 가지게 된 이유는 패프트 이미지를 보고 나서임
- 디퓨전은 텍스트와 이미지와의 상관관계를 학습하는 방식임

26:36
오토 인코더의 장점
- 오토 인코더는 학습 데이터도 별로 필요가 없음
- 입력으로 넣은 게 출력으로 제대로 나오는지를 학습시켜버리면 됨

31:26
디퓨전의 정의
- 논문을 보면 수식이 엄청 많음
- 수식에 대한 의미를 강의를 듣고 나면 마지막에 알게 될 것임
- 디퓨전에 대해서 설명해 드릴 것임

36:42
마르코프 체인의 성질
- 마르코프 체인은 어떠한 사건들이 있을 때 s10이라는 사건은 바로 전 스 9에 의해서만 표현이 되는 것임
- 마르코프 성질은 앞에 있는 사건들은 다 무시하고 내가 현재 일어나는 어떤 현상은 내 바로 전에 일나는 사건에만 영향을 받음

39:36
포드 프로세스
- 포드 프로세스는 수학에 의해서 결정이 됨
- 네트워크가 하고자 하는 건 학습을 통해서 어떠한 인풋 이미지 노이즈가 들어왔을 때 얼마만큼 뺄 건지를 학습을 해서 x 제로를 만드는 것임
- 학습시킬 때는 깨끗한 원본 이미지를 넣어가지고 노이즈를 조금씩 조금씩 조금씩 넣어가지고 맨 오른쪽 그림처럼 화이트 노이즈처럼 만들어놓고 역으로 노이즈를 조금씩 조금씩 조금씩 빼서 원본 이미지가 나오게끔 설계를 해놓고 los function을 만드는 것임

43:59
노이즈 제거
- 단어들 임베딩 한다는 거는 앞뒤 단어 사이에 있는 단어를 법률적으로 한다는 것임
- 그림 자체가 이렇게 형태를 우리는 손으로 따라갈 수 있는데 기계 보고 그렇게 억지로 시킬 수 없으니까 랜덤하게 샘플링 하면서 점들의 상관관계에 비슷한 것을 추출하는 것임
- 노이즈를 빼면 원본이 나오니까 어쨌든 노이즈를 빼내가는 과정을 학습하는데 그게 화이트 노이즈에서 빼니까 모든 걸 다 만들 수 있는 것임

46:46
하이레졸루션 기술
- 하이레졸루션 기술을 개발하려고 하는 와중에 노이즈를 추가하고 빼는 기술을 넣어보니까 이미지 생성 기술과 비슷한 것 같다고 결론이 나옴
- 전체 구조는 스텝 수가 길수록 더하기 노이즈 더 했는 거 빼는 단계가 많은 거임
- 네트워크는 이런 식으로 진행이 될 거임

49:24
포드 프로세스
- 포드 프로세스는 인풋으로 이미지로부터 로이즈화 가는 과정이었음
- 포드 프로세스의 노이즈를 더해가면서 완전한 가우시안 노이즈로 보내는 과정을 포워드 프로세스라고 함
- 엑스 티는 루 1반에서 베타 티에 베타는 3수임
- 베레시 오터 코드를 하면 알 수 있음

53:48


59:45
배터 스케줄링에 따른 밴드들
- 배터 스케줄링에 따라서 어떤 디퓨전의 노이즈화 하는 보통 이미지 같은 경우에 밴드들이라고 함
- 논문에서 봤을 때는 그냥 일반적으로 다 밴드들 1번 2번 3번 이렇게 공통적으로 다 줘버린 것 같음
- 코사인 상태에 의해서 베타를 점점 늘려나간다라고 보면 될 것 같음

1:04:39
딥러닝 논문에서 걱정하는 것
- 논문에서는 하이퍼 파라미터가 정의가 되었을 때 왜 그렇게 정의를 했는지 제시가 됨
- 딥러닝 논문에서는 잘못된 것이 많음
- 딥러닝은 추정과 가정하는 것 때문에 대부분 나오는 게 휴리스틱과 값과 분포, 확률과 분포로 걱정함

1:10:05
베타도 러너블
- 베타도 러너블하다는 거는 베타를 찾는 신경망이 따로 있든지 아니면 신경망에 임베딩해서 해서 거기서 나온 값일 수도 있음
- 질문자의 말이 정확하다는 가정 하에 학습해서 그런 식을 찾아봤을 수도 있기는 한데 제가 이 ddpm 논문을 읽은 지가 꽤 돼가지고 학습을 했어서 저렇게 찾았었는지는 잘 기억이 나지 않음

1:12:52
리버스 프로세스
- 리버스 프로세스를 하기 위해서 노이즈로부터 이미지를 만들기 위해서 네트워크가 학습을 함
- 포워드 프로세스 안에 들어가 보면 이미지로부터 어떤 노이즈를 만들 때 어떤 알파 베타에 의해서 x 제로부터 저렇게 어떤 셈과 덧셈으로 표현할 수가 있음
- 리버스 프로세스를 좀 더 간단하게 해보면 엑스 제로라는 이미지로부터 어떤 라즈 x 티로 그러면 저 라즈 x 티는 제트티라는 어떤 표한 어떤 가우시라는 디스트리베이션에 해당이 됨
- 가오션 디스트리지 크션으로부터 다시 맥스 제로 프라임을 또 만들 수 있음
- 베리에이션 오토인 코드는 오토 인코더의 여러 조각으로 볼 수 있음
- 베리에이션 오토인 코더는 원본하고 똑같이 만드는 오토 인코더의 버전임
- 베리에이션 오토인 코더의 여러 조각으로 볼 수 있는 디퓨션은 베리에이션 오토인코더의 여러 조각으로 볼 수 있음

1:18:03
베레이션 오토인 코더
- 베레이션 오토인 코더가 하나의 피스고 디퓨전은 이 피스들로 여러 개 묶으면 디퓨전임
- 각각의 12번의 수식을 해석하면 맨 첫 번째 터는 레글라이제이션 터임
- 포워드 프로세스에 의해서 xt라는 분포와 네트워크가 만드는 분포와 실제 분포가 얼마나 닮아 있는지를 평가하는 매트릭임

1:20:48
디노이징 프로세스
- 레그랜테이션 텀을 왜 보유하지 않느냐 하면 우리 엑스 라지 티는 우리는 포워드 수식에 의해서 결국 라지 티로 가는 가우이랑 분포가 된다는 가정을 하고 만드는 게 대표장임
- 수식에 의해서 가오이라이임
- 마지막으로 오른 전의 리크스 션 텀은 논문에서는 픽셀로 하면서 설명을 했던 것 같음
- 내가 그 개념을 정확하게 잘 이해를 하지 못했음
- 어떻게 넘어갔냐면 많이 주어졌을 때 x 제로로 리크스 션하는 턴이잖아요. 우리 엑스와 말 x 제로는 굉장히 작은 대타라는 것을 알고 있음
- 그렇기 때문에 리컨스럭션 턴도 굳이 계산을 고려할 필요가 없는 작은 값이거나 혹은 굳이 학습에 영향을 주지 않는 상수값 베타로도 수가 있기 때문에 더 펌은 무시를 해도 무방하다라고 해석을 해서 요 디노이징 프로세스 이 가운데 있는 초록색만 계산을 하면 되겠다라고 이런 식으로 디퓨전을 넘어가려고 했음

1:24:09
로스 함수의 중요성
- 로스 함수가 가장 중요함
- 로스 함수를 무시하면 안 됨
- 케이엘 다이버전스는 가오 시안 분포와 가오시한 분포 사이의 거리를 정량적으로 표현하는 수식임

1:27:14
디피전을 이용한 논문
- 디피전을 이용한 첫 번째 논문은 아니지만 대중적으로 가장 많이 알려진 논문이라고 보시면 됨
- 디피전을 이용한 포드 프로세스와 노이즈로 보내는 리버스 프로세스 두 가지가 있음
- 노이즈 x t로부터 x 제로는 직관적인 재해석임
- x 제로와 t가 주어졌을 때 t 마이너스 1이라는 분포 수식을 전개해도 가능한 이유는 x 제로가 이미 주어진 디토닉하게 주어진 식이라고 봐도 되기 때문임
- pdf 펑션으로 표현할 수 있음

1:33:04
뉴랑 베리에이션
- 뉴랑 베리에이션으로 표현을 할 때 표현법을 수식을 전개해 나감
- 수식을 전개했을 때 xt가 주어졌을 때 xt 마이너스 1은 뮤랑 비언스의 디스트리뷰션으로 표현할 수 있음
- xt는 x 제로로부터 노이즈가 만든 거라고 함
- 코르는 프로세스로 표현할 수 있음

1:34:57
노이즈를 맞추는 네트워크
- 네트워크가 해야 될 일은 노이즈를 맞추는 것임
- 노이즈를 어떤 노이즈를 떼는지를 구하면 됨
- 노이즈가 실제 우리가 들어간 노이즈는 엑스 제로로부터 알 수 있음
- 노이즈가 많이 낀 애들부터 학습을 잘해야 함

1:39:59
로스의 절실론
- 증명 과정 필요 없음
- 알파 베타는 이미 정해져 있음
- 로이즈만 세팅해 가면 됨
- 로스는 네트워크 유네이나 레지돌 블록 같은 형식으로 잘 설계해서 액션런이 나오면 ft 만들 때 넣었던 절실론이랑 정답 비교하면 됨

1:41:34
딥 뉴럴렛을 이용한 노이즈 학습
- 포워드는 수학적으로 계산이 되고 리버스 프로세스 같은 경우에는 우리가 노이즈를 추정을 해야 됨
- 어떤 노이즈가 이미지에 가해져서 지금 이런 화이트 노이즈처럼 생겼는지를 찾아야 되기 때문에 원래 들어가는 로이즈와 우리가 추정하는 로이즈의 차를 이용하면 로스 함수를 정할 수 있음
- 딥 뉴럴렛으로 노이즈를 학습시키면 됨


clovanote.naver.com